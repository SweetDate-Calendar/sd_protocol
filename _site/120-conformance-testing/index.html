<h1 id="conformance-testing">Conformance Testing</h1>

<p>The <strong>SweetDate Conformance Testing</strong> suite is a set of tools and protocols that verify whether a client implementation of the <strong>SweetDate Protocol</strong> behaves as expected.</p>

<p>This mechanism is designed to ensure <strong>trust</strong>, <strong>interoperability</strong>, and <strong>predictability</strong> across implementations in different programming languages.</p>

<h2 id="purpose">Purpose</h2>

<p>While the <strong>SweetDate CLI</strong> scaffolds starter templates from the official protocol definition, the <strong>Conformance Testing Suite</strong> ensures that the resulting implementation <strong>correctly and fully implements the protocol</strong>.</p>

<p>It does so by coordinating an automated interaction between:</p>
<ul>
  <li>a <strong>Language-specific Test Runner</strong> (maintained by the implementor), and</li>
  <li>a <strong>Universal Conformance Driver</strong> (provided by the SweetDate project).</li>
</ul>

<p>Together, these components validate whether the commands, error handling, and edge case behavior conform to the expectations defined in the protocol specification.</p>

<hr />

<h2 id="why-it-matters">Why It Matters</h2>

<p>Client implementations are developed independently across ecosystems.<br />
Conformance testing gives implementors and integrators <strong>confidence</strong> that:</p>

<ul>
  <li>The library behaves exactly like others (regardless of language)</li>
  <li>Protocol-breaking bugs are caught early</li>
  <li>New protocol versions can be tested before releasing</li>
</ul>

<p>It also enables <strong>third-party distribution</strong>: packages can be labeled as <em>SweetDate Certified</em> once they pass the conformance suite.</p>

<hr />

<h2 id="testing-strategy">Testing Strategy</h2>

<p>The Conformance Suite uses an <strong>active test pattern</strong> inspired by contract-based testing:</p>

<ol>
  <li>The <strong>Conformance Driver</strong> sends a command to the client implementation asking it to run a specific scenario (e.g., <code class="language-plaintext highlighter-rouge">EVENTS.CREATE with missing start_time</code>).</li>
  <li>The client runs that test internally and returns a <strong>success/failure signal</strong>.</li>
  <li>The driver verifies the result and logs/report outcomes in a common format.</li>
</ol>

<p>This avoids the risk of <strong>false compliance</strong> caused by incomplete test coverage inside language-specific test suites.</p>

<hr />

<h2 id="components">Components</h2>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Conformance Driver</strong></td>
      <td>A generic orchestrator that issues standardized test commands and receives test results from the client.</td>
    </tr>
    <tr>
      <td><strong>Language-specific Test Runner</strong></td>
      <td>A program or script (written in Ruby, PHP, Elixir, etc.) that accepts test requests and executes matching scenarios using the actual client implementation.</td>
    </tr>
    <tr>
      <td><strong>Protocol Spec</strong></td>
      <td>The source of truth. All test cases are derived from the SDIP JSON files, ensuring alignment across all tooling.</td>
    </tr>
    <tr>
      <td><strong>Result Format</strong></td>
      <td>JSON and writes to the console</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="example-flow">Example Flow</h2>

<p>```mermaid
sequenceDiagram
  participant Driver as Conformance Driver
  participant Impl as Ruby Client (Test Runner)</p>

<p>Driver-»Impl: { “command”: “EVENTS.CREATE”, “scenario”: “missing start_time” }
  Impl–»Driver: { “status”: “fail”, “error_code”: “MISSING_FIELD” }
  Driver-»Impl: { “command”: “EVENTS.DELETE”, “scenario”: “valid event” }
  Impl–»Driver: { “status”: “pass” }</p>
